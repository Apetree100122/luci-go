// Copyright 2019 The LUCI Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package buffer

import (
	"context"
	"sync"
	"time"

	"go.chromium.org/luci/common/errors"
	"go.chromium.org/luci/common/retry"
)

// Batch represents a collection of individual work items and associated
// metadata.
//
// Batches are are cut by the Channel according to BatchOptions, and can be
// manipulated by ErrorFn and SendFn.
//
// ErrorFn and SendFn may manipulate the contents of the Batch (Data and Meta)
// to do things such as:
//   * Associate a UID with the Batch (e.g. in the Meta field) to identify it to
//     remote services for deduplication.
//   * Remove already-processed items from Data in case the SendFn partially
//     succeeded.
//
// The dispatcher uses Batch.Len() to account for how many items are currently
// buffered. The length of a Batch is `min(len(Data), Batch's original length)`.
type Batch struct {
	// Data is the actual items in the batch.
	Data []interface{}

	// Meta is an object which dispatcher.Channel will treat as totally opaque;
	// You may manipulate it in SendFn or ErrorFn as you see fit. This can be used
	// for e.g. associating a nonce with the Batch for retries.
	Meta interface{}

	// id is a 1-based counter which is generated by Buffer when the Batch
	// is created. Within a Buffer it is monotonically increasing.
	id uint64

	// retry is the retry.Iterator associated with this Batch. Its Next method
	// will be called when it is NACK'd.
	retry retry.Iterator

	// nextSend is the next timestamp after which this Batch is eligible for
	// sending.
	//
	// While the batch is the `currentBatch` in the buffer, this timestamp
	// represents the deadline for cutting this batch.
	nextSend time.Time

	// countedSize is the length of this Batch as the Buffer counts it. It starts
	// as the original value of len(Batch.Data) and can decrease if
	// len(Batch.Data) is smaller on a NACK().
	countedSize int
}

// LeasedBatch is produced from Buffer.LeaseOne.
//
// It contains Batch, and you must call ACK or NACK on it, exactly once.
//
// Calling ACK/NACK a second time will panic.
type LeasedBatch struct {
	*Batch

	mu sync.Mutex

	// The size of the Batch at the time we leased it.
	leasedSize int

	// The Buffer that this Batch belongs to.
	buf *bufferImpl
}

// Returns non-nil pointer to b.buf, setting it to nil in the process.
//
// panics if b.buf == nil.
func (b *LeasedBatch) detachBuffer() *bufferImpl {
	b.mu.Lock()
	buf := b.buf
	b.buf = nil
	b.mu.Unlock()

	if buf == nil {
		panic(errors.New("LeasedBatch may only have ACK/NACK called exactly once"))
	}

	return buf
}

// ACK records that all the items in the batch have been processed.
//
// The Batch is no longer tracked by the associated Buffer.
func (b *LeasedBatch) ACK() {
	b.detachBuffer().ackImpl(b.leasedSize)
}

// NACK analyzes the current state of Batch.Data, potentially freeing space in
// the Buffer's heap if the current Buffer.Data length is smaller than when the
// Batch was originally leased.
//
// The Batch will be re-enqueued unless:
//   * The Batch's retry Iterator returns retry.Stop
//   * The Buffer has a DropOldestBatch policy and a new Batch has been added to
//     the Buffer.
func (b *LeasedBatch) NACK(ctx context.Context, err error) {
	b.detachBuffer().nackImpl(ctx, err, b.Batch, b.leasedSize)
}
